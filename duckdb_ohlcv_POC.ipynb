{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database/db/ohlcv_data.db\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='config/.env')\n",
    "database_path = os.getenv('DATABASE_PATH')\n",
    "print(database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.gather.indian_equity import gather_ohlcv_indian_equity\n",
    "\n",
    "symbols , data = gather_ohlcv_indian_equity(timeframe='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: duckdb in /usr/local/lib/python3.11/site-packages (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "def save_symbol_data_as_parquet(symbol , data , base_directory='database/finstore', market_name='indian_equity', timeframe='1d'):\n",
    "\n",
    "    # Define the directory path based on the market name, timeframe, and symbol\n",
    "    dir_path = os.path.join(base_directory, f\"market_name={market_name}\", f\"timeframe={timeframe}\", str(symbol))\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    # Define the file path for the Parquet file\n",
    "    file_path = os.path.join(dir_path, 'ohlcv_data.parquet')\n",
    "\n",
    "    # Write the dataframe to a Parquet file with ZSTD compression\n",
    "    data.to_parquet(file_path, index=False, compression='zstd')\n",
    "\n",
    "# Example of usage\n",
    "# data_dict = {'AAPL': df_aapl, 'GOOGL': df_googl}  # This should be your data dictionary input\n",
    "# save_data_as_parquet(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol, data in ohlcv_data.items():\n",
    "    save_symbol_data_as_parquet(symbol , data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def read_parquet_for_symbol(symbol, market_name='indian_equity', timeframe='1d', base_directory='database/finstore'):\n",
    "    \"\"\"\n",
    "    Reads the Parquet file for a given symbol and returns it as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        symbol (str): The symbol to read data for.\n",
    "        market_name (str): The market name (default: 'indian_equity').\n",
    "        timeframe (str): The timeframe (default: '1d').\n",
    "        base_directory (str): The base directory where data is stored (default: 'database/finstore').\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the symbol and its corresponding DataFrame.\n",
    "    \"\"\"\n",
    "    # Define the directory path and file path based on the input parameters\n",
    "    file_path = os.path.join(base_directory, f\"market_name={market_name}\", f\"timeframe={timeframe}\", symbol, 'ohlcv_data.parquet')\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"Parquet file not found for symbol '{symbol}' at '{file_path}'\")\n",
    "\n",
    "    # Create a DuckDB connection (in-memory for this operation)\n",
    "    conn = duckdb.connect()\n",
    "    conn.execute(\"PRAGMA threads=4\")  # Use multiple threads for parallel reading\n",
    "\n",
    "    # Read the entire Parquet file into a DataFrame\n",
    "    df = conn.execute(f\"SELECT * FROM read_parquet('{file_path}')\").fetchdf()\n",
    "\n",
    "    # Close the DuckDB connection\n",
    "    conn.close()\n",
    "\n",
    "    return symbol, df\n",
    "\n",
    "def read_all_symbols(symbols, market_name='indian_equity', timeframe='1d', base_directory='database/finstore'):\n",
    "    \"\"\"\n",
    "    Reads the Parquet files for all given symbols in parallel and returns a dictionary with the results.\n",
    "\n",
    "    Parameters:\n",
    "        symbols (list): List of symbols to read data for.\n",
    "        market_name (str): The market name (default: 'indian_equity').\n",
    "        timeframe (str): The timeframe (default: '1d').\n",
    "        base_directory (str): The base directory where data is stored (default: 'database/finstore').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with symbols as keys and their corresponding DataFrames as values.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        # Use ProcessPoolExecutor to read each symbol's data in parallel\n",
    "        futures = {executor.submit(read_parquet_for_symbol, symbol, market_name, timeframe, base_directory): symbol for symbol in symbols}\n",
    "        for future in futures:\n",
    "            symbol = futures[future]\n",
    "            try:\n",
    "                symbol, df = future.result()\n",
    "                results[symbol] = df\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading data for symbol {symbol}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example of usage\n",
    "# symbols_list = ['AAPL', 'GOOGL', 'MSFT']  # List of symbols to read\n",
    "# data_dict = read_all_symbols(symbols_list, market_name='indian_equity', timeframe='1d')\n",
    "# print(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.fetch.indian_equity import fetch_symbol_list_indian_equity\n",
    "symbols = fetch_symbol_list_indian_equity(index_name='nse_eq_symbols')\n",
    "dict_data = read_all_symbols(symbols , market_name='indian_equity', timeframe='1d')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
