{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database/db/ohlcv_data.db\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='config/.env')\n",
    "database_path = os.getenv('DATABASE_PATH')\n",
    "print(database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def read_parquet_for_symbol(symbol, market_name='indian_equity', timeframe='1d', base_directory='database/finstore'):\n",
    "    \"\"\"\n",
    "    Reads the Parquet file for a given symbol and returns it as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        symbol (str): The symbol to read data for.\n",
    "        market_name (str): The market name (default: 'indian_equity').\n",
    "        timeframe (str): The timeframe (default: '1d').\n",
    "        base_directory (str): The base directory where data is stored (default: 'database/finstore').\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the symbol and its corresponding DataFrame.\n",
    "    \"\"\"\n",
    "    # Define the directory path and file path based on the input parameters\n",
    "    file_path = os.path.join(base_directory, f\"market_name={market_name}\", f\"timeframe={timeframe}\", symbol, 'ohlcv_data.parquet')\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"Parquet file not found for symbol '{symbol}' at '{file_path}'\")\n",
    "\n",
    "    # Create a DuckDB connection (in-memory for this operation)\n",
    "    conn = duckdb.connect()\n",
    "    conn.execute(\"PRAGMA threads=4\")  # Use multiple threads for parallel reading\n",
    "\n",
    "    # Read the entire Parquet file into a DataFrame\n",
    "    df = conn.execute(f\"SELECT * FROM read_parquet('{file_path}')\").fetchdf()\n",
    "\n",
    "    # Close the DuckDB connection\n",
    "    conn.close()\n",
    "\n",
    "    return symbol, df\n",
    "\n",
    "def read_all_symbols(symbols, market_name='indian_equity', timeframe='1d', base_directory='database/finstore'):\n",
    "    \"\"\"\n",
    "    Reads the Parquet files for all given symbols in parallel and returns a dictionary with the results.\n",
    "\n",
    "    Parameters:\n",
    "        symbols (list): List of symbols to read data for.\n",
    "        market_name (str): The market name (default: 'indian_equity').\n",
    "        timeframe (str): The timeframe (default: '1d').\n",
    "        base_directory (str): The base directory where data is stored (default: 'database/finstore').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with symbols as keys and their corresponding DataFrames as values.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        # Use ProcessPoolExecutor to read each symbol's data in parallel\n",
    "        futures = {executor.submit(read_parquet_for_symbol, symbol, market_name, timeframe, base_directory): symbol for symbol in symbols}\n",
    "        for future in futures:\n",
    "            symbol = futures[future]\n",
    "            try:\n",
    "                symbol, df = future.result()\n",
    "                results[symbol] = df\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading data for symbol {symbol}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example of usage\n",
    "# symbols_list = ['AAPL', 'GOOGL', 'MSFT']  # List of symbols to read\n",
    "# data_dict = read_all_symbols(symbols_list, market_name='indian_equity', timeframe='1d')\n",
    "# print(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "def insert_data_duckdb(market_name, symbol_name, timeframe, df, indicators_df):\n",
    "    \"\"\"Write technical indicators data to a parquet file.\"\"\"\n",
    "    base_directory = 'database/finstore'\n",
    "    file_path = os.path.join(base_directory, f\"market_name={market_name}\", f\"timeframe={timeframe}\", symbol_name, 'technical_indicators.parquet')\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    # Add symbol_id and timeframe columns\n",
    "    indicators_df['symbol_id'] = symbol_name\n",
    "    indicators_df['timeframe'] = timeframe\n",
    "    \n",
    "    # Reorder columns to match the desired format\n",
    "    formatted_df = indicators_df[['symbol_id', 'timeframe', 'timestamp', 'indicator_name', 'indicator_value']]\n",
    "    \n",
    "    # Ensure indicator_value is float\n",
    "    formatted_df.loc[:, 'indicator_value'] = formatted_df['indicator_value'].astype(float)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        # Read the existing data\n",
    "        existing_df = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Append the current indicator DataFrame to the existing data\n",
    "        formatted_df = pd.concat([existing_df, formatted_df], ignore_index=True)\n",
    "    \n",
    "    # Write the formatted DataFrame to a parquet file\n",
    "    formatted_df.to_parquet(file_path, index=False)\n",
    "    #print(f'{symbol_name} file written to {file_path}.')\n",
    "\n",
    "def process_symbol(symbol, df, market_name, timeframe, calculation_func, calculation_kwargs):\n",
    "    \"\"\"\n",
    "    Process data for each symbol and write technical indicators to a parquet file.\n",
    "    \n",
    "    Args:\n",
    "    symbol (str): Symbol name.\n",
    "    df (pd.DataFrame): OHLCV data DataFrame.\n",
    "    market_name (str): Market name.\n",
    "    timeframe (str): Timeframe (e.g., '1d', '1h').\n",
    "    calculation_func (callable): Function to calculate indicators.\n",
    "    calculation_kwargs (dict): Keyword arguments for the indicator calculation function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform indicator calculations\n",
    "    try:\n",
    "        indicators_df = calculation_func(df, **calculation_kwargs) \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating {calculation_func.__name__} for {symbol}: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Write the indicators data to a parquet file\n",
    "    insert_data_duckdb(market_name=market_name, symbol_name=symbol, timeframe=timeframe, df=df, indicators_df=indicators_df)\n",
    "\n",
    "def fetch_calculate_and_insert_duckdb(ohlcv_data, market_name, timeframe, calculation_func, **calculation_kwargs):\n",
    "    use_multiprocessing = True\n",
    "    \n",
    "    if use_multiprocessing:\n",
    "        with ProcessPoolExecutor(max_workers=6) as executor:\n",
    "            futures = [\n",
    "                executor.submit(process_symbol, symbol, df, market_name, timeframe, calculation_func, calculation_kwargs)\n",
    "                for symbol, df in ohlcv_data.items()\n",
    "            ]\n",
    "            for _ in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing symbols\"):\n",
    "                pass  # Wait for all futures to complete\n",
    "    else:\n",
    "        for symbol, df in tqdm(ohlcv_data.items(), desc=\"Processing symbols\"):\n",
    "            process_symbol(symbol, df, market_name, timeframe, calculation_func, calculation_kwargs)\n",
    "\n",
    "    print(f\"{calculation_func.__name__} calculation and insertion completed for market: {market_name} and timeframe: {timeframe}\")\n",
    "\n",
    "# Example usage\n",
    "# from data.fetch.indian_equity import fetch_symbol_list_indian_equity\n",
    "# symbol_list = fetch_symbol_list_indian_equity(index_name='nse_eq_symbols')\n",
    "# fetch_calculate_and_insert_duckdb('indian_equity', '1d', symbol_list, your_calculation_function, **your_calculation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        317.625000\n",
      "1        333.500000\n",
      "2        350.174988\n",
      "3        367.674988\n",
      "4        351.237488\n",
      "           ...     \n",
      "1247    1011.200012\n",
      "1248     963.799988\n",
      "1249     976.549988\n",
      "1250    1010.000000\n",
      "1251    1022.849976\n",
      "Name: close, Length: 1252, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ohlcv_data = read_all_symbols(symbol_list, market_name='indian_equity', timeframe='1d')\n",
    "for symbol , df in ohlcv_data.items():\n",
    "    print(df)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'open', 'high', 'low', 'close', 'volume', 'market_name',\n",
      "       'timeframe'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for symbol , df in ohlcv_data.items():\n",
    "    print(df.columns)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21335/3016613451.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  formatted_df['indicator_value'] = formatted_df['indicator_value'].astype(float)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol_name</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>indicator_name</th>\n",
       "      <th>indicator_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-19 00:00:00</th>\n",
       "      <td>360ONE.NS</td>\n",
       "      <td>1d</td>\n",
       "      <td>ema_10</td>\n",
       "      <td>317.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-20 00:00:00</th>\n",
       "      <td>360ONE.NS</td>\n",
       "      <td>1d</td>\n",
       "      <td>ema_10</td>\n",
       "      <td>320.511364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-23 00:00:00</th>\n",
       "      <td>360ONE.NS</td>\n",
       "      <td>1d</td>\n",
       "      <td>ema_10</td>\n",
       "      <td>325.904750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-24 00:00:00</th>\n",
       "      <td>360ONE.NS</td>\n",
       "      <td>1d</td>\n",
       "      <td>ema_10</td>\n",
       "      <td>333.499339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-25 00:00:00</th>\n",
       "      <td>360ONE.NS</td>\n",
       "      <td>1d</td>\n",
       "      <td>ema_10</td>\n",
       "      <td>336.724457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04 00:00:00</th>\n",
       "      <td>360ONE.NS</td>\n",
       "      <td>1d</td>\n",
       "      <td>ema_10</td>\n",
       "      <td>1034.167424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-07 00:00:00</th>\n",
       "      <td>360ONE.NS</td>\n",
       "      <td>1d</td>\n",
       "      <td>ema_10</td>\n",
       "      <td>1021.373345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08 00:00:00</th>\n",
       "      <td>360ONE.NS</td>\n",
       "      <td>1d</td>\n",
       "      <td>ema_10</td>\n",
       "      <td>1013.223644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-09 00:00:00</th>\n",
       "      <td>360ONE.NS</td>\n",
       "      <td>1d</td>\n",
       "      <td>ema_10</td>\n",
       "      <td>1012.637527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-10 00:00:00</th>\n",
       "      <td>360ONE.NS</td>\n",
       "      <td>1d</td>\n",
       "      <td>ema_10</td>\n",
       "      <td>1014.494336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1252 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    symbol_name timeframe indicator_name  indicator_value\n",
       "timestamp                                                                \n",
       "2019-09-19 00:00:00   360ONE.NS        1d         ema_10       317.625000\n",
       "2019-09-20 00:00:00   360ONE.NS        1d         ema_10       320.511364\n",
       "2019-09-23 00:00:00   360ONE.NS        1d         ema_10       325.904750\n",
       "2019-09-24 00:00:00   360ONE.NS        1d         ema_10       333.499339\n",
       "2019-09-25 00:00:00   360ONE.NS        1d         ema_10       336.724457\n",
       "...                         ...       ...            ...              ...\n",
       "2024-10-04 00:00:00   360ONE.NS        1d         ema_10      1034.167424\n",
       "2024-10-07 00:00:00   360ONE.NS        1d         ema_10      1021.373345\n",
       "2024-10-08 00:00:00   360ONE.NS        1d         ema_10      1013.223644\n",
       "2024-10-09 00:00:00   360ONE.NS        1d         ema_10      1012.637527\n",
       "2024-10-10 00:00:00   360ONE.NS        1d         ema_10      1014.494336\n",
       "\n",
       "[1252 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for symbol , df in ohlcv_data.items():\n",
    "    indi_df =calculate_ema(df, length=10)\n",
    "    break\n",
    "\n",
    "indi_df = indi_df.reset_index()\n",
    "indi_df = indi_df.set_index('timestamp')\n",
    "# Add symbol_id and timeframe columns\n",
    "indi_df['symbol_name'] = symbol\n",
    "indi_df['timeframe'] = '1d'\n",
    "\n",
    "# Reorder columns to match the desired format\n",
    "formatted_df = indi_df[['symbol_name', 'timeframe', 'indicator_name', 'indicator_value']]\n",
    "\n",
    "# Ensure indicator_value is float\n",
    "formatted_df['indicator_value'] = formatted_df['indicator_value'].astype(float)\n",
    "formatted_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.fetch.indian_equity import fetch_symbol_list_indian_equity\n",
    "symbol_list = fetch_symbol_list_indian_equity(index_name='nse_eq_symbols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing symbols: 100%|██████████| 1673/1673 [00:15<00:00, 109.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_ema calculation and insertion completed for market: indian_equity and timeframe: 1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing symbols: 100%|██████████| 1673/1673 [00:16<00:00, 101.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_ema calculation and insertion completed for market: indian_equity and timeframe: 1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing symbols: 100%|██████████| 1673/1673 [00:17<00:00, 95.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_ema calculation and insertion completed for market: indian_equity and timeframe: 1d\n"
     ]
    }
   ],
   "source": [
    "from utils.calculation.indicators import calculate_ema\n",
    "fetch_calculate_and_insert_duckdb(ohlcv_data, 'indian_equity', '1d', calculate_ema, length=100)\n",
    "fetch_calculate_and_insert_duckdb(ohlcv_data, 'indian_equity', '1d', calculate_ema, length=200)\n",
    "fetch_calculate_and_insert_duckdb(ohlcv_data, 'indian_equity', '1d', calculate_ema, length=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.calculation.supertrend import faster_supertrend\n",
    "from utils.calculation.slope_r2 import calculate_exponential_regression_optimized\n",
    "from utils.calculation.optimized_indicators import calculate_spike_optimized, detect_large_gap_optimized, calculate_average_volume_optimized\n",
    "fetch_calculate_and_insert_duckdb(ohlcv_data, 'indian_equity', '1d', faster_supertrend, period=7, multiplier=3)\n",
    "fetch_calculate_and_insert_duckdb(ohlcv_data, 'indian_equity', '1d', calculate_exponential_regression_optimized, window=90)\n",
    "fetch_calculate_and_insert_duckdb(ohlcv_data, 'indian_equity', '1d', calculate_exponential_regression_optimized, window=30)\n",
    "fetch_calculate_and_insert_duckdb(ohlcv_data, 'indian_equity', '1d', calculate_exponential_regression_optimized, window=15)\n",
    "fetch_calculate_and_insert_duckdb(ohlcv_data, 'indian_equity', '1d', calculate_spike_optimized, lookback_period=90, spike_threshold=0.15)\n",
    "fetch_calculate_and_insert_duckdb(ohlcv_data, 'indian_equity', '1d', detect_large_gap_optimized, lookback_period=90, gap_threshold=0.15)\n",
    "fetch_calculate_and_insert_duckdb(ohlcv_data, 'indian_equity', '1d', calculate_average_volume_optimized, lookback_period=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finstore.finstore import Finstore\n",
    "Finstore = Finstore(market_name='indian_equity', timeframe='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_data = Finstore.read.symbol_list(symbol_list=symbol_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
